{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = pickle.load(open(\"train_set.p\", \"rb\"))\n",
    "test_set = pickle.load(open(\"test_set.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['well stock finished &amp; listed, living room moved around, new editing done &amp; fitted in a visit to the in-laws. #productivityatitsfinest #happy', '3'], [\"@someuser but it's so aesthetically pleasing omg\", '3'], ['#smile every morning to a positive head start with your #clients relations', '3'], ['i just spent $40 on big little sis tomorrow and i am beyond happy about it #saw  #mums', '3'], ['@someuser happy birthday to the most beautiful cheerful sister ever, llnp üíï‚ù£üéâ', '3'], ['blake lively is flawless', '3'], ['watching avatar and wondering why i took so long to watch this *collapses in a joyous heap*', '3'], ['happy birthday shorty. stay fine stay breezy stay wavy @someuser üòò', '3'], [\"oi @someuser you've absolutely fucking killed me.. 30 mins later im still crying with laughter.. grindah.. grindah... ü§ì  hahahahahahaha\", '3'], ['grateful for all the hungry people in my life! hungry to learn, change, grow, help, etc - not sure anybody has it better! #relentless', '3']]\n"
     ]
    }
   ],
   "source": [
    "print(train_set[30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_of_hastags(tweet):\n",
    "    return tweet.count(\"#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@someuser i hate post con blues! but i avoided the plague too yay!! yay constant hand sanitizer!!! 2\n@someuser yes lia!! join the dark side!! 2\n@someuser peanut butter???? you some kinda pervert??  2\n@someuser peanut butter???? you some kinda pervert?? #awful 2\n"
     ]
    }
   ],
   "source": [
    "def get_no_of_mult_punctuation(tweet):\n",
    "    return len(re.findall(r\"[?!]{2,}\", tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well stock finished &amp; listed, living room moved around, new editing done &amp; fitted in a visit to the in-laws. #productivityatitsfinest #happy\n['well stock finished', 'stock finished &', 'finished & listed', '& listed ,', 'listed , living', ', living room', 'living room moved', 'room moved around', 'moved around ,', 'around , new', ', new editing', 'new editing done', 'editing done &', 'done & fitted', '& fitted in', 'fitted in a', 'in a visit', 'a visit to', 'visit to the', 'to the in-laws', 'the in-laws .', 'in-laws . #productivityatitsfinest', '. #productivityatitsfinest #happy']\n"
     ]
    }
   ],
   "source": [
    "def get_ngrams(tweet, n):\n",
    "    tknzr = TweetTokenizer()\n",
    "    tokens = tknzr.tokenize(tweet)\n",
    "    l = []\n",
    "    for ngram in ngrams(tokens, n):\n",
    "        l.append(' '.join(str(i) for i in ngram))\n",
    "\n",
    "    return l\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
